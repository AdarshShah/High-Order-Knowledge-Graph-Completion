{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from preprocess.process_dataset import get_dgl_graph\n",
    "from preprocess.subgraph_extraction import extract_subgraph\n",
    "from preprocess.graph_to_simplicial_complex import get_simplicial_complex, get_embeddings, _get_simplices, random_sample\n",
    "from hodgelaplacians import HodgeLaplacians\n",
    "from global_parameters import device\n",
    "from layers.simplicial_convolution import SimplicialAttentionLayer, SimplicialConvolution\n",
    "import numpy as np\n",
    "import timeit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "        For Reproducibility: Sets the seed of the entire notebook.\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Sets a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Author mentions this dataset to have 10 classes. but the labels shows more than 1500 classes with severe class imbalance.\n",
    "dataset = 'cat_edge_DAWN' # problem with dataset\n",
    "num_classes = 10\n",
    "simplex_order=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Our model performs best on this dataset. Results are available below\n",
    "dataset = 'cat_edge_cooking'\n",
    "num_classes = 20\n",
    "simplex_order=4\n",
    "max_nodes = [10, 100, 150, 200] # parameters to control the sparsity of the sampled graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# AUC > 0.5 for all classes but does not achieve the highest auc. The model with highest AUC has AUC < 0.5 for some classes.\n",
    "dataset = 'cat_edge_MAG_10'\n",
    "num_classes = 10\n",
    "simplex_order=4\n",
    "max_nodes = [10, 80, 100, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Our model performs best on this dataset. Results are available below\n",
    "dataset = 'cat_edge_algebra_questions'\n",
    "num_classes = 32\n",
    "simplex_order = 4\n",
    "max_nodes = [3, 20, 25, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> loading cat_edge_MAG_10 dataset\n",
      "> loading nx_graph from cache\n",
      "> loading dgl_graph from cache\n"
     ]
    }
   ],
   "source": [
    "graph, nx_graph = get_dgl_graph(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hyperparameters for graph subsampling controlling the number of nodes sampled at each hop corresponding to each simplex order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplex, order, label = random_sample(dataset, num_classes=num_classes, max_dim=simplex_order)\n",
    "to_remove = frozenset(simplex)\n",
    "subgraph = extract_subgraph(simplex, graph, h=4, enclosing_sub_graph=True, max_nodes_per_hop=max_nodes[order])\n",
    "isolated_nodes = ((subgraph.in_degrees() == 0) & (subgraph.out_degrees() == 0)).nonzero().squeeze(1)\n",
    "subgraph.remove_nodes(isolated_nodes)\n",
    "simplex_labels = get_simplicial_complex(subgraph, graph, nx_graph, dataset, num_classes)\n",
    "embeddings, laplacians, boundaries, idx = get_embeddings(simplex_labels, to_remove, num_classes, dim=simplex_order)\n",
    "print('Laplacians:',[ laplacian.shape if laplacian is not None else 0 for laplacian in laplacians])\n",
    "print('Boundaries:',[ boundary.shape if boundary is not None else 0 for boundary in boundaries])\n",
    "print('Embeddings',[ embedding.shape if embedding is not None else 0 for embedding in embeddings])\n",
    "print('Label',label)\n",
    "print('Order:',order, 'Index:',idx)\n",
    "print('subgraph : ', subgraph.num_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from models.model import SimplicialModel1, BaseGNN\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'/home/adarsh/H-KGC/datasets/{dataset}/logs')\n",
    "gs = 0\n",
    "\n",
    "cm = SimplicialModel1(num_classes, dim=simplex_order, device=device).to(device)\n",
    "baseGnn = BaseGNN(num_classes, dim=simplex_order, device=device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        b = 1\n",
    "        while b!=0:\n",
    "            simplex, order, label = random_sample(dataset, num_classes=num_classes, max_dim=simplex_order)  # randomly sample \n",
    "            to_remove = frozenset(simplex)\n",
    "            try:\n",
    "                subgraph = extract_subgraph(simplex, graph, h=4, enclosing_sub_graph=True, max_nodes_per_hop=max_nodes[order])\n",
    "                isolated_nodes = ((subgraph.in_degrees() == 0) & (subgraph.out_degrees() == 0)).nonzero().squeeze(1)\n",
    "                subgraph.remove_nodes(isolated_nodes)\n",
    "                simplex_labels = get_simplicial_complex(subgraph, graph, nx_graph, dataset, num_classes)\n",
    "                embeddings, laplacians, boundaries, idx = get_embeddings(simplex_labels, to_remove, num_classes, dim=simplex_order)\n",
    "                b = 0\n",
    "            except:\n",
    "                pass\n",
    "        return embeddings, laplacians, boundaries, order, idx, label, subgraph\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "\n",
    "def custom_collate(X):\n",
    "    return X[0]\n",
    "\n",
    "dataloader = DataLoader(MyDataset(), batch_size=1, num_workers=12, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "optim1 = torch.optim.Adam(cm.parameters(), lr=1e-5, betas=(0.8, 0.9))\n",
    "optim2 = torch.optim.Adam(baseGnn.parameters(), lr=1e-5, betas=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [26:30<00:00,  6.29it/s] \n"
     ]
    }
   ],
   "source": [
    "gs = 0\n",
    "timeout = 0\n",
    "loss1 = 0 \n",
    "loss2 = 0\n",
    "ep = 0\n",
    "with tqdm(dataloader) as tepoch:\n",
    "    for embeddings, laplacians, boundaries, order, idx, label, subgraph in tepoch:\n",
    "        label, subgraph = label.to(device), subgraph.to(device)\n",
    "        embeddings = [ x.to(device) if x is not None else None for x in embeddings]\n",
    "        laplacians = [ x.to(device) if x is not None else None for x in laplacians]\n",
    "        boundaries = [ x.to(device) if x is not None else None for x in boundaries]\n",
    "\n",
    "        try:\n",
    "            pred = cm(embeddings, laplacians, boundaries, order, idx).squeeze()\n",
    "            loss1 += torch.nn.functional.binary_cross_entropy_with_logits(pred, label, reduction='sum')\n",
    "            \n",
    "            \n",
    "            subgraph = subgraph.to(device)\n",
    "            pred = baseGnn(subgraph, embeddings[0], order).squeeze()\n",
    "            loss2 += torch.nn.functional.binary_cross_entropy_with_logits(pred, label, reduction='sum')\n",
    "\n",
    "            # if ep%4==0:\n",
    "            optim1.zero_grad()\n",
    "            loss1.backward() \n",
    "            optim1.step()\n",
    "            optim2.zero_grad()\n",
    "            loss2.backward()\n",
    "            optim2.step()\n",
    "            writer.add_scalars('Train Loss',{'Simplicial CNN': loss1.item(), 'Vanilla GNN': loss2.item()}, gs)\n",
    "\n",
    "            gs+=1\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            loss1 = 0\n",
    "            loss2 = 0\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following analysis established increasing the density of sampled subgraph increases the autograd function's time. \\\n",
    "> The preprocessing steps are efficient enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# profile = cProfile.Profile()\n",
    "# profile.runcall(train)\n",
    "# ps = pstats.Stats(profile)\n",
    "# ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5000/10000 [13:07<13:07,  6.35it/s]  \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ep = 0\n",
    "    H0 = []\n",
    "    H1 = []\n",
    "    H2 = []\n",
    "    H3 = []\n",
    "    labels0 = []\n",
    "    labels1 = []\n",
    "    with tqdm(dataloader) as tepoch:\n",
    "        for embeddings, laplacians, boundaries, order, idx, label, subgraph in tepoch:\n",
    "            label, subgraph = label.to(device), subgraph.to(device)\n",
    "            embeddings = [ x.to(device) if x is not None else None for x in embeddings]\n",
    "            laplacians = [ x.to(device) if x is not None else None for x in laplacians]\n",
    "            boundaries = [ x.to(device) if x is not None else None for x in boundaries]\n",
    "            try:\n",
    "                if order > 0: # makes no sense to perform node classification since node embedding will be 0.\n",
    "                    pred0 = (torch.sum(embeddings[0][:order+1], dim=0)!=0).long().squeeze()\n",
    "                    pred1 = (torch.prod(embeddings[0][:order+1], dim=0)!=0).long().squeeze()\n",
    "                    H0.append((pred0==label).long())\n",
    "                    H1.append((pred1==label).long())\n",
    "                    labels0.append(label)\n",
    "                pred2 = baseGnn(subgraph, embeddings[0], order).squeeze()\n",
    "                pred3 = cm(embeddings, laplacians, boundaries, order, idx).squeeze()\n",
    "                # H1.append((torch.round(torch.sigmoid(pred1))==label).long())\n",
    "                # H2.append((torch.round(torch.sigmoid(pred2))==label).long())\n",
    "                H2.append(torch.sigmoid(pred2))\n",
    "                H3.append(torch.sigmoid(pred3))\n",
    "                labels1.append(label)\n",
    "                ep += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                if ep>5000:\n",
    "                    break\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "H0, H1, H2, H3, labels0, labels1 = torch.stack(H0), torch.stack(H1), torch.stack(H2), torch.stack(H3), torch.stack(labels0), torch.stack(labels1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC is better with Simplicial GNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cooking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51911765, 0.51687063, 0.64657611, 0.56582912, 0.53607287,\n",
       "       0.79921146, 0.89523652, 0.63794053, 0.8654661 , 0.53434365,\n",
       "       0.70567372, 0.57837271, 0.7574628 , 0.6710991 , 0.80998623,\n",
       "       0.62403343, 0.68920112, 0.72598578, 0.59171389, 0.89688298])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with union operation\n",
    "A = roc_auc_score(labels0.cpu().numpy(), H0.cpu().numpy(), average=None)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04292717, 0.03817016, 0.08655175, 0.06787192, 0.04947368,\n",
       "       0.18579349, 0.33087085, 0.07921127, 0.26067347, 0.04367146,\n",
       "       0.12316499, 0.06941253, 0.16130686, 0.10876274, 0.19959445,\n",
       "       0.07345928, 0.10307504, 0.14082343, 0.05486939, 0.3230642 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with intersection operation\n",
    "B = roc_auc_score(labels0.cpu().numpy(), H1.cpu().numpy(), average=None)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37811031, 0.36809629, 0.42570043, 0.3550341 , 0.37381868,\n",
       "       0.45743081, 0.55753017, 0.3365722 , 0.5992221 , 0.45996608,\n",
       "       0.44736236, 0.29196856, 0.61854158, 0.39790765, 0.49849615,\n",
       "       0.42312672, 0.36396334, 0.43439689, 0.4093961 , 0.68208262])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with vanilla GNN\n",
    "C = roc_auc_score(labels1.cpu().numpy(), H2.cpu().numpy(), average=None)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84475226, 0.85036659, 0.85169009, 0.82380886, 0.86718511,\n",
       "       0.81179283, 0.79583433, 0.8389978 , 0.80167683, 0.85957148,\n",
       "       0.84274947, 0.83867689, 0.82096279, 0.84412427, 0.83087325,\n",
       "       0.84676633, 0.85862406, 0.84563099, 0.84680219, 0.78288959])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with Simplicial Relational CNN with attention\n",
    "D = roc_auc_score(labels1.cpu().numpy(), H3.cpu().numpy(), average=None)\n",
    "D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MAG 10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52428818, 0.51135579, 0.49754948, 0.55378302, 0.48126553,\n",
       "       0.44210296, 0.59513961, 0.56304752, 0.53522168, 0.52181259])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with union operation\n",
    "A = roc_auc_score(labels0.cpu().numpy(), H0.cpu().numpy(), average=None)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20325682, 0.22952984, 0.15315415, 0.19937588, 0.24867593,\n",
       "       0.18684313, 0.28170267, 0.16078714, 0.18261795, 0.18116036])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with intersection operation\n",
    "B = roc_auc_score(labels0.cpu().numpy(), H1.cpu().numpy(), average=None)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3858733 , 0.80293204, 0.55857195, 0.66615752, 0.38909283,\n",
       "       0.66376762, 0.90069397, 0.86292019, 0.76499934, 0.8100246 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with vanilla GNN\n",
    "C = roc_auc_score(labels1.cpu().numpy(), H2.cpu().numpy(), average=None)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58232999, 0.56074748, 0.632423  , 0.6086886 , 0.60977494,\n",
       "       0.68004316, 0.5343723 , 0.57903281, 0.56640076, 0.56211353])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with Simplicial Relational CNN with attention\n",
    "D = roc_auc_score(labels1.cpu().numpy(), H3.cpu().numpy(), average=None)\n",
    "D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Algebra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "mask = (labels0.sum(dim=0)!=0)\n",
    "labels0 = labels0[:,mask]\n",
    "labels1 = labels1[:,mask]\n",
    "H0 = H0[:,mask]\n",
    "H1 = H1[:,mask]\n",
    "H2 = H2[:,mask]\n",
    "H3 = H3[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60316548, 0.87834481, 0.83421509, 0.68688603, 0.48682088,\n",
       "       0.27459993, 0.56340304, 0.48334466, 0.48322785, 0.7470315 ,\n",
       "       0.41616334, 0.37599125, 0.45169791, 0.23253115, 0.47801609,\n",
       "       0.50146823, 0.3800952 , 0.39444916, 0.36623563, 0.48744842,\n",
       "       0.41693383, 0.31519287, 0.50080043, 0.41800005, 0.33560242,\n",
       "       0.46415809, 0.339969  ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with union operation\n",
    "A = roc_auc_score(labels0.cpu().numpy(), H0.cpu().numpy(), average=None)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.43371069e-01, 3.58126787e-01, 3.16738202e-01, 1.78085657e-01,\n",
       "       5.96591312e-02, 1.33761370e-04, 1.24590954e-01, 1.05375915e-01,\n",
       "       1.11379784e-01, 1.58971410e-01, 5.98372883e-02, 6.00560569e-02,\n",
       "       1.09904333e-01, 5.00000000e-02, 7.65059132e-02, 3.33333333e-01,\n",
       "       1.00000000e-01, 6.29124278e-02, 3.47515758e-02, 9.18181941e-02,\n",
       "       0.00000000e+00, 3.25270263e-02, 5.00000000e-01, 2.23404255e-01,\n",
       "       0.00000000e+00, 1.22641509e-01, 2.73972603e-02])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with intersection operation\n",
    "B = roc_auc_score(labels0.cpu().numpy(), H1.cpu().numpy(), average=None)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3367712 , 0.67368304, 0.30531657, 0.60858596, 0.31999774,\n",
       "       0.68652722, 0.34995078, 0.45771285, 0.72481168, 0.2977402 ,\n",
       "       0.51995944, 0.58102021, 0.6737459 , 0.26598403, 0.32966697,\n",
       "       0.25858755, 0.46942063, 0.61100428, 0.47171285, 0.57529979,\n",
       "       0.44915865, 0.3705732 , 0.35779975, 0.69518344, 0.32587163,\n",
       "       0.81403198, 0.61005244])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with vanilla GNN\n",
    "C = roc_auc_score(labels1.cpu().numpy(), H2.cpu().numpy(), average=None)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67236035, 0.65286182, 0.67391915, 0.66077263, 0.64479844,\n",
       "       0.81709554, 0.65022366, 0.70133256, 0.63881042, 0.68741815,\n",
       "       0.74258188, 0.77596711, 0.60744694, 0.84673106, 0.76292101,\n",
       "       0.84137966, 0.77096748, 0.72950116, 0.76455381, 0.78663134,\n",
       "       0.82129677, 0.79102923, 0.84795534, 0.70298919, 0.875418  ,\n",
       "       0.57521282, 0.69547062])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC with Simplicial Relational CNN with attention\n",
    "D = roc_auc_score(labels1.cpu().numpy(), H3.cpu().numpy(), average=None)\n",
    "D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtech-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c8a66ee3e6b3d2731e4e1d203879b7efbef813706e5767cef09de0fdb5c447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
