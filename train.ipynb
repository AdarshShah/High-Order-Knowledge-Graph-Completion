{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from preprocess.process_dataset import get_dgl_graph\n",
    "from preprocess.subgraph_extraction import extract_subgraph\n",
    "from preprocess.graph_to_simplicial_complex import get_simplicial_complex, get_embeddings, device, _get_simplices, random_sample\n",
    "from hodgelaplacians import HodgeLaplacians\n",
    "from layers.simplicial_convolution import SimplicialAttentionLayer, SimplicialConvolution\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cat_edge_cooking'\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cat_edge_DAWN'\n",
    "num_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> loading nx_graph from cache\n",
      "> loading dgl_graph from cache\n"
     ]
    }
   ],
   "source": [
    "graph, nx_graph = get_dgl_graph(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacians: [torch.Size([4, 4]), torch.Size([4, 4]), 0, 0]\n",
      "Boundaries: [torch.Size([1, 4]), torch.Size([4, 4]), 0, 0]\n",
      "Embeddings [torch.Size([4, 20]), torch.Size([4, 20]), 0, 0]\n",
      "Label tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1.], device='cuda:0')\n",
      "Order: 1 Index: 0\n"
     ]
    }
   ],
   "source": [
    "simplex, order, label = random_sample(dataset, num_classes=num_classes, max_dim=4)\n",
    "to_remove = frozenset(simplex)\n",
    "subgraph = extract_subgraph(simplex, graph, h=4, enclosing_sub_graph=True, max_nodes_per_hop=30)\n",
    "simplex_labels = get_simplicial_complex(subgraph, graph, nx_graph, dataset, num_classes)\n",
    "embeddings, laplacians, boundaries, idx = get_embeddings(simplex_labels, to_remove, num_classes, dim=4)\n",
    "print('Laplacians:',[ laplacian.shape if laplacian is not None else 0 for laplacian in laplacians])\n",
    "print('Boundaries:',[ boundary.shape if boundary is not None else 0 for boundary in boundaries])\n",
    "print('Embeddings',[ embedding.shape if embedding is not None else 0 for embedding in embeddings])\n",
    "print('Label',label)\n",
    "print('Order:',order, 'Index:',idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import SimplicialModel1\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'/home/adarsh/H-KGC/datasets/{dataset}/logs')\n",
    "gs = 0\n",
    "\n",
    "cm = SimplicialModel1(num_classes, dim=4, device=device).to(device)\n",
    "optim = torch.optim.Adam(cm.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    gs = 0\n",
    "    for ep in tqdm(range(500)):\n",
    "        simplex, order, label = random_sample(dataset, num_classes=num_classes, max_dim=4)\n",
    "        to_remove = frozenset(simplex)\n",
    "        subgraph = extract_subgraph(simplex, graph, h=4, enclosing_sub_graph=True, max_nodes_per_hop=50)\n",
    "        simplex_labels = get_simplicial_complex(subgraph, graph, nx_graph, dataset, num_classes)\n",
    "        embeddings, laplacians, boundaries, idx = get_embeddings(simplex_labels, to_remove, num_classes, dim=4)\n",
    "\n",
    "        pred = cm(embeddings, laplacians, boundaries, order, idx).squeeze()\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        writer.add_scalar('train loss',loss.item(), gs)\n",
    "        gs+=1\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [00:52<06:28,  1.11it/s]"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "profile = cProfile.Profile()\n",
    "profile.runcall(train)\n",
    "ps = pstats.Stats(profile)\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:23<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    H = []\n",
    "    for ep in tqdm(range(50)):\n",
    "        simplex, order, label = random_sample(dataset, num_classes=num_classes, max_dim=4)\n",
    "        to_remove = frozenset(simplex)\n",
    "        subgraph = extract_subgraph(simplex, graph, h=4, enclosing_sub_graph=True, max_nodes_per_hop=30)\n",
    "        simplex_labels = get_simplicial_complex(subgraph, graph, nx_graph, dataset, num_classes)\n",
    "        embeddings, laplacians, boundaries, idx = get_embeddings(simplex_labels, to_remove, num_classes, dim=4)\n",
    "\n",
    "        pred = cm(embeddings, laplacians, boundaries, order, idx).squeeze()\n",
    "        H.append((torch.round(torch.sigmoid(pred))==label).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7000, 0.6800, 0.6600, 0.6800, 0.6800, 0.6200, 0.5000, 0.6200, 0.5800,\n",
       "        0.7200, 0.5600, 0.7000, 0.6400, 0.6800, 0.5800, 0.6400, 0.6800, 0.5800,\n",
       "        0.6200, 0.5800], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.stack(H),dim=0)/len(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtech-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c8a66ee3e6b3d2731e4e1d203879b7efbef813706e5767cef09de0fdb5c447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
